import time
import cv2
import numpy as np
from collections import deque
from openvino.runtime import Core

def non_max_suppression(predictions, conf_thres=0.5, iou_thres=0.5):
    """åŸºäº OpenCV çš„ NMS"""
    boxes = predictions[:, :4].tolist()
    scores = predictions[:, 4].tolist()

    indices = cv2.dnn.NMSBoxes(boxes, scores, conf_thres, iou_thres)
    if len(indices) == 0:
        return []

    return predictions[indices.flatten()]


# -------------------------------
# 1. åˆå§‹åŒ– OpenVINO æ¨ç†å¼•æ“
# -------------------------------
ie = Core()
model_ir_path = "yolov11s-face.xml"
model = ie.read_model(model=model_ir_path)
compiled_model = ie.compile_model(model=model, device_name="GPU")

input_layer = compiled_model.input(0)
output_layer = compiled_model.output(0)
font = cv2.FONT_HERSHEY_SIMPLEX
# -------------------------------
# 2. æ‘„åƒå¤´ä¸FPSåˆå§‹åŒ–
# -------------------------------
url = "http://10.201.171.127:8088/mjpeg1"
#url = "http://10.201.171.123:81/stream"
cap = cv2.VideoCapture(url)
# cap = cv2.VideoCapture(0)
if not cap.isOpened():
    raise RuntimeError("Cannot open camera")
fps_queue = deque(maxlen=10)

# -------------------------------
# 3. ä¸»å¾ªç¯
# -------------------------------
while cap.isOpened():
    # å…ˆæ¸…ç©ºç¼“å­˜å¸§ï¼ˆæœ€å¤šè¯» N æ¬¡ï¼‰
    for _ in range(5):  # N å¯è°ƒï¼Œè¶Šå¤§è¶Šæ–°ï¼Œè¶Šå°è¶Šç¨³
        cap.grab()

    success, frame = cap.read()
    if not success:
        break

    start = time.time()
    scale_x = frame.shape[1] / 640  # 1920 / 640 = 3.0
    scale_y = frame.shape[0] / 640  # 1080 / 640 = 1.6875
    # é¢„å¤„ç†ï¼šResize + å½’ä¸€åŒ– + NCHW
    resized = cv2.resize(frame, (640, 640))
    input_tensor = resized.transpose(2, 0, 1)[np.newaxis, ...].astype(np.float32) / 255.0

    # æ¨ç†è¾“å‡º (1, 6, N) â†’ (N, 6)
    raw_output = compiled_model([input_tensor])[output_layer]
    raw_output = np.squeeze(raw_output).T  # â†’ (N, 5) or (N, 6)

    # å¦‚æœåªæœ‰5åˆ—ï¼Œè¡¥ç±»åˆ«åˆ—ä¸º0
    if raw_output.shape[1] == 5:
        cls = np.zeros((raw_output.shape[0], 1))
        raw_output = np.hstack([raw_output, cls])

    cx = raw_output[:, 0]
    cy = raw_output[:, 1]
    w = raw_output[:, 2]
    h = raw_output[:, 3]
    conf = raw_output[:, 4]
    cls = raw_output[:, 5]

    # è§£ç ä¸ºå·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡
    x1 = cx - w / 2
    y1 = cy - h / 2
    x2 = cx + w / 2
    y2 = cy + h / 2

    decoded_boxes = np.stack([x1, y1, x2, y2, conf, cls], axis=1)

    # ç½®ä¿¡åº¦è¿‡æ»¤
    filtered = decoded_boxes[decoded_boxes[:, 4] > 0.5]

    # NMS
    final_boxes = non_max_suppression(filtered, conf_thres=0.5, iou_thres=0.4)

    # if len(final_boxes) > 0:
    #     print("ğŸ§  Sample Box:", final_boxes[0])
    # -------------------------------
    # 4. å¯è§†åŒ–
    # -------------------------------
    annotated_frame = frame.copy()

    for det in final_boxes:
        x1, y1, x2, y2, conf, cls = det

        # ä¿®æ­£åæ ‡ï¼šç¡®ä¿å·¦ä¸Šè§’å’Œå³ä¸‹è§’é¡ºåº
        x1, x2 = sorted([x1, x2])
        y1, y2 = sorted([y1, y2])

        # ç¼©æ”¾æ¡†åæ ‡åˆ°åŸå›¾å°ºå¯¸
        x1 *= scale_x
        x2 *= scale_x
        y1 *= scale_y
        y2 *= scale_y

        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])
        cx = (x1 + x2) // 2 #200
        cy = (y1 + y2) // 2 #50
        area = (x2 - x1) * (y2 - y1) #60000æ—¶æ‚¬åœ
        # print(f"ğŸ“ Detected Box - cx: {cx}, cy: {cy}, area: {area}")
        # âœ… æ­£ç¡®ç»˜åˆ¶ï¼šåæ ‡é¡ºåºåº”ä¸º (x, y)ï¼Œå³ (åˆ—, è¡Œ)
        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 128, 255), 2)
        cv2.circle(annotated_frame, (cx, cy), 4, (0, 255, 0), -1)

        # # æ–‡æœ¬ä¿¡æ¯
        # font = cv2.FONT_HERSHEY_SIMPLEX
        # cv2.putText(annotated_frame, f"({cx},{cy})", (x1, max(y2 + 15, 15)),
        #             font, 0.5, (255, 0, 0), 1)
        # cv2.putText(annotated_frame, f"A={area}", (x1, y2 + 35),
        #             font, 0.5, (255, 0, 0), 1)

    # FPS è®¡ç®—
    end = time.time()
    fps = 1.0 / (end - start)
    fps_queue.append(fps)
    avg_fps = sum(fps_queue) / len(fps_queue)

    # cv2.putText(annotated_frame, f"FPS: {fps:.2f}", (10, 30),
    #             font, 0.5, (0, 255, 0), 2)
    # cv2.putText(annotated_frame, f"Avg: {avg_fps:.2f}", (10, 60),
    #             font, 0.5, (0, 255, 255), 2)

    # æ˜¾ç¤ºå›¾åƒ
    cv2.imshow("OpenVINO YOLOv8 Inference", annotated_frame)
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

# æ¸…ç†èµ„æº
cap.release()
cv2.destroyAllWindows()